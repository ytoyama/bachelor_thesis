\documentclass[twocolumn,a4paper]{ltjarticle}

\usepackage{luatexja}
\usepackage{nlp}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{scrextend}
\usepackage{setspace}
\usepackage{color}
\usepackage{tabularx}
\usepackage{makecell}
\usepackage[compact]{titlesec}

\makeatletter
\let\tti@includegraphics\includegraphics
\renewcommand{\includegraphics}[1]{%
    \tti@includegraphics[width=\linewidth]{#1}}
\makeatother


\title{\textbf{
  %パラグラフベクトルとNNによる\\
  文書・文間及びカテゴリ間の関係を考慮したレーティング予測 \\
  Rating Prediction Reflecting Relations \\
  among a Document, Sentences and Categories \\
  %via Pragraph Vector and Neural Network\\
}}

\author{
  \begin{tabular}{c c c}
    %外山 洋太 & \hspace{4ex}三輪 誠\hspace{4ex} & 佐々木 裕 \\
    %\multicolumn{3}{c}{豊田工業大学}
    \makecell{外山 洋太\\Yota Toyama}
    & \hspace{4ex}\makecell{三輪 誠\\Makoto Miwa}\hspace{4ex}
    & \makecell{佐々木 裕\\Yutaka Sasaki} \\
    \multicolumn{3}{c}{\makecell{豊田工業大学\\Toyota Technological Institute}}
  \end{tabular}
}
\date{\texttt{\{sd12056, makoto-miwa, yutaka.sasaki\}@toyota-ti.ac.jp}}



\begin{document}

\maketitle

\section{序論}

%企業において商品の評判分析のためのレビューの評判分類は重要な問題である。
%何万件という大量のレビューデータを人手で処理することは難しく、
%計算機による自動化が望まれる。
%その中でレビューを複数のカテゴリにおいて分類する問題がある。
%カテゴリとは、宿泊施設のレビューを例にすると、サービス、立地、食事等の
%レーティングが付けられる各項目のことである。
%しかし、多くの評判分類の手法は一つのカテゴリに対するものである。
%また、この問題に関する従来手法\cite{fujitani15}は、
%文間の関係性を考慮しておらず、
%カテゴリ間については考慮しているものの深い関係性を捉えることができていない。

近年、評判分類において、ニューラルネットワークを用いた手法
\cite{nal14,rie14,duyu15}が
提案されており、従来の手法を上回る正答率を達成している。
ニューラルネットワークを分類問題に用いる利点はまず
層の数を増やすことによって入力の深い繋がりを考慮できることである。
例えば、文毎の素性を入力とすれば文間の関係性を捉えることができる。
さらに、多カテゴリの分類問題においてはカテゴリ間の関係性を捉えた分類が
実現できる。
しかし、評判分類に関する多くの研究は1つのカテゴリにおける二値分類問題を
対象としている。

文や文章の意味表現の学習手法として、単語と文章の分散表現を同時に学習する
パラグラフベクトル\cite{quoc14}がある。
これは評判分類問題に対して優れた性能を示している。
しかし、文書全体にパラグラフベクトルを用いた場合、
分類時に文の位置関係を考慮できない。

本研究は、複数カテゴリにおける評判分類について、
%パラグラフベクトル\cite{quoc14}とニューラルネットワークを用いて
文書及び文間の関係とカテゴリ間の関係を同時に考慮した分類を実現することを
目的とする。

%提案手法では、パラグラフベクトル\cite{quoc14}によって
%生成された各レビューの文書ベクトルと文ベクトルを
%ニューラルネットワークによる分類器において分類しレーティング予測を行う。
%楽天トラベルのデータセットを用いた実験において、
%提案手法は従来手法\cite{fujitani15}に対して約2pp上回る正答率を
%示した。
%レーティングの平均二乗誤差(RMSE)を元にした評価基準では、
%従来手法\cite{fujitani15}において弱点となっていたカテゴリについて
%それを上回る結果を示した。

%ただし、その他のカテゴリでは従来手法\cite{fujitani15}との間に有意な差は
%見られなかった。
%また、パラグラフベクトルが文書と文について適用された場合、
%文書ベクトルと文ベクトルはいくらか異なる特徴を捉えていることが示された。



\section{関連研究}

\subsection{隠れ状態を用いたホテルレビューのレーティング予測}

藤谷ら\cite{fujitani15}は複数のカテゴリにおける評判分類問題に対して、
Multi-Instance Multi-Label learning for Relation Extraction (MIML-RE)
\cite{mihai12}モデルを用いた手法を提案している。
その手法では、レビュー内の各文毎に予測した隠れレーティングから
レビュー全体のレーティングを予測する。
文毎のレーティングからレビュー全体のレーティングを予測する際の
カテゴリ間の繋がりを手動で変化させカテゴリ間の関係性を考慮している。
各文の素性にはBag Of Words (BOW)またはBag Of n-gramを用いている。
各文毎に隠れレーティングを予測することによって
0.4832の正答率が得られることが示された。
また、カテゴリ間の繋がりによって正答率が変化することも示されている。

この手法では、文同士の位置関係を考慮しておらず、
カテゴリ間については考慮しているものの深い関係性を捉えることができていない。


\subsection{パラグラフベクトル}

パラグラフベクトルは、文や文章といった大きな単位の言語表現の意味表現を
学習する手法である。
これは、Continuous BOW (CBOW)またはSkip-gram\cite{yoshua03}という
単語の意味表現の学習手法を応用した手法である。
ここではCBOWを応用したDistributed Memory model of Paragraph Vectors (PV-DM)
について説明する。
PV-DMはBOWと異なり、単語の並び順を考慮した文や文章の分散表現を
生成することができる。

以下に具体的なアルゴリズムを示す。
ここでは文章の意味表現を学習する場合について考える。
学習の概略を図\ref{fig:ParagraphVector}に示す。
まず、意味表現を学習する対象となる文章に含まれる単語を
初めから一つずつ読んでいく。
その際、現在の単語及びその周辺の単語、現在の文章について、
式\ref{eq:ParagraphVector}に示す目的関数$L$を最大化するように
各パラメータの学習を行う。
\begin{gather}
  L = \frac{1}{T} \sum^{T}_{t = k} \log p(w_t | w_{t-k}, ..., w_{t-1}),
    \label{eq:ParagraphVector} \\
  p(w_t | w_{t-k}, ..., w_{t-1}) = \frac{e^{y_{w_t}}}{\sum_i e^{y_i}},
    \nonumber \\
  y = b + Uh(w_{t-k}, ..., w_{t-1}, d; W, D) \nonumber
\end{gather}
ここで、$d$は文章、$w_i$は単語、$W$は全ての単語の分散表現を表す行列、
$D$は全ての文章の分散表現を表す行列である。
$k$はウィンドウサイズ、$T$は現在の文章に含まれる単語数である。
ある単語の周辺を表す区間をウィンドウという。
$p$はsoftmax関数により正規化された、文脈から現在の単語が導かれることの
尤度である。
$p$を構成する$y$は現在の単語とウィンドウ内の単語及び現在の文章から導出される。
$h(w_{t-k}, ..., w_{t-1}, d; W, D)$は引数となるベクトルを平均したベクトル
または結合したベクトルを返す関数である。

PV-DMによって得られたパラグラフベクトルは評判分類問題において
BOW等に比べ高い正答率を示すことが示されている。
しかし、文書全体にパラグラフベクトルを用いる場合、文同士の位置関係が
分類時に考慮できない。

\begin{figure}[t!]
  \includegraphics{fig/paragraph_vector.png}
  \caption{パラグラフベクトルの学習の概略}
  \label{fig:ParagraphVector}
\end{figure}


\subsection{ニューラルネットワークを用いた評判分析}

ニューラルネットワークを用いた評判分析の手法が、Nalら\cite{nal14}、
Rieら\cite{rie14}、Duyuら\cite{duyu15}等によって提案されている。
これらの方法に共通するのは、単語の意味表現から畳み込みニューラルネットワークと
全結合ニューラルネットワークを用いて分類を行うことである。
まず、単語の意味表現から畳み込みニューラルネットワークを
用いて単語同士の関係を捉えた特徴量を抽出する。
その後、そこから得られた文書全体の特徴量を
全結合ニューラルネットワークの入力とし多値または二値分類を行う。
また、Duyuら\cite{duyu15}とNalら\cite{nal14}の手法は
ニューラルネットワークのモデルの中にパラメータとして
単語の意味表現を取り込んでいる。これにより、特定の分類問題に対して
それを直に微調整することが可能となる。



\section{提案手法}

提案手法では、PV-DMによってレビュー内の文書全体及び各文の分散表現を
生成し、それらをニューラルネットワークの入力として分類を行う。
文毎の分散表現を用いることで文同士の位置関係を考慮し、
ニューラルネットワークによる分類器を用いることで
文間及びカテゴリ間の深い関係性を捉えることを目指す。
提案手法の入力はレビューである文書と正解レーティングの組の集合、
出力は各文書について予測されたカテゴリ毎のクラスである。
以下に提案手法の処理の流れを示す。

初めに、PV-DMを用いて、
各レビューの文書ベクトルとそれに含まれる各文のベクトルを生成する。
文書ベクトルと文ベクトルについては別々に学習し生成する。
%式\ref{eq:PVObjective}に示す目的関数$L_d$を最大化するように学習を行う。
%\begin{multline}
%  L_d = \sum^{T}_{t = n + 1} \{ \log \sigma(s(w_t, w_{t-n}, ..., w_{t-1}, d)) \\
%        + \sum^{k}_{w_{t}' \sim P_n}
%        \log(1 - \sigma(s(w_{t}', w_{t-n}, ..., w_{t-1}, d))) \},
%    \label{eq:PVObjective} \\
%\end{multline}
%\begin{gather}
%  s(w_t, w_{t - n}, ..., w_{t - 1}, d)
%    = W_{map}(w_t)
%      \cdot \begin{bmatrix} W(w_{t - n}) \\ \vdots
%      \\ W(w_{t - 1}) \\ D(d) \end{bmatrix} \nonumber
%\end{gather}
%ここで、$T$は現在の文章内の単語数、$t$は現在の単語位置、$d$は現在の文章、
%$w_i$は位置$i$にある単語、$n$はウィンドウサイズである。
%$W(w_i)$は単語$w_i$に相当する単語ベクトルを単語行列$W$から抜き出す関数を表す。
%$D(d)$は文章$d$に相当する文章ベクトルを文章行列$D$から抜き出す関数を表す。
%関数$s(w_t, w_0, ..., w_n, d)$はある単語とそれが出現する文脈との類似度を
%計算する。
%行列$W_{map}$は内積によって文脈と単語との類似度を計算するための単語毎
%のベクトルを保持する。
%文章行列内の各文章ベクトルはレビュー全体を表す文書ベクトル、または、
%各レビュー内の文ベクトルを表す。
%$\sigma$はシグモイド関数である。
%また、式\ref{eq:PVObjective}の中括弧内の右項はネガティブサンプリングを
%表す。
%ネガティブサンプリングとは、文脈外の単語をデータセットにおける出現確率で
%サンプリングし、それらと文脈の意味が遠ざかるように学習する手法である。
%$w_{t}' \sim P_n$は文脈外の単語$w_{t}'$を単語の出現頻度$P_n$によって
%サンプリングすることを示す。
%ただし、出現頻度は極端に頻出する単語の影響を抑えるため
%各単語に対して3/4乗している。
%現在の単語と同じ単語や同一回の学習で一度サンプリングされた単語は
%サンプリングしない。
式\ref{eq:ParagraphVector}の目的関数における$h$には
引数のベクトルを結合する関数を用いる。
また、学習の高速化のため、Quocら\cite{quoc14}によって
用いられている階層的softmaxの代替として、ネガティブサンプリングを行う。
ネガティブサンプリングとは、文脈外の単語をデータセットにおける出現確率で
サンプリングし、それらと文脈の意味が遠ざかるように学習する手法である。
ただし、出現頻度は極端に頻出する単語の影響を抑えるため
各単語に対して3/4乗している。
現在の単語と同じ単語や同一回の学習で一度サンプリングされた単語は
サンプリングしない。

次に、各レビュー内の全ての文ベクトルに対して重み付け平均を行い、
圧縮された文ベクトルを生成する。
この過程により、各レビューで疎らだった文の数を統一する。
式\ref{eq:WeightedAverageSV}に重み付け平均によって圧縮した
文ベクトル$t_{i_{part}}$を示す。
各文ベクトルは圧縮後の各文ベクトルと位置が近いほど重みが大きくなるように
重み付け平均する。
\begin{gather}
  \mathbf{t}_{i_{part}} = \sum_{i_{sent}}
                          \frac{w(x_{i_{part}}(i_{sent}))}
                               {|\sum_{i_{sent}'} w(x_{i_{part}}(i_{sent}'))|}
                          \mathbf{s}_{i_{sent}},
  \label{eq:WeightedAverageSV} \\
  x_{i_{part}}(i_{sent}) = \frac{i_{sent} - i_{part}}{\#partitions},
  \nonumber \\
  w(x) = \begin{cases}
    \frac{1}{2} (\cos(\pi|x|) + 1) &\text{if $|x| <= 1$} \\
    0 &\text{otherwise}
  \end{cases} \nonumber
\end{gather}
ここで、$i_{sent}$はレビュー内の文のインデックス、
$\#partitions$は重み付け平均された後の文ベクトルの数、
$i_{part}$は重み付け平均された後の文ベクトルのインデックス、
$\mathbf{s}_{i_{sent}}$は文ベクトルである。
\footnote{重み付けの関数には$\cos$関数の他に、
$x$に対して線形に重みを減少させるような関数や、
単純に文を区画毎に平均するような関数も考えられる。
区画毎に平均する関数は他の2つより正答率が低く、線形な関数と
$\cos$関数はほぼ同じ正答率を示したため、$\cos$関数を採用した。}

最後に、分類器によってレーティング予測を行う。
分類器は全結合ニューラルネットワークによって構成される。
図\ref{fig:MyModel}に各層の結合の様子を示す。
\begin{figure}[t!]
  \includegraphics{fig/model.png}
  \caption{全結合ニューラルネットワークによる分類器}
  \label{fig:MyModel}
\end{figure}
入力層はレビュー毎の文書ベクトルと圧縮された文ベクトルの結合ベクトルである。
ニューラルネットワークの活性化関数には、シグモイド関数を用いる。
また、出力層はカテゴリの数とラベルの数の積だけのユニットを持ち、
各ユニットの出力はあるカテゴリ内であるクラスが選ばれることの
正規化されていない対数確率を表す。
ニューラルネットワークは式\ref{eq:NNObjective}に示す目的関数$E$を
最小化するように学習を行う。
\begin{gather}
  E = - \sum^{N}_{n = 1} \sum^{C}_{c = 1} \sum^{K}_{k = 1}
        d_{nck} \log{y_{ck}(x_n; w)},
  \label{eq:NNObjective} \\
  y_{ck}(x_n; w) = \frac{e^{u_{ck}(x_n; w)}}
                        {\sum^{K}_{j = 1} e^{u_{cj}(x_n; w)}} \nonumber
\end{gather}
各ユニットの出力はカテゴリ毎に交差エントロピー誤差関数によって
損失に変換される。
ここで、$u_{ck}$は出力層のユニットの出力値、$y_{ck}$はカテゴリ$c$において
クラス$k$が選ばれる確率、$w$はニューラルネットワークのパラメータである。
$d_{nck}$は$n$番目の文書がカテゴリ$c$でクラス$k$ならば1、
それ以外で0となる値である。
$N$はミニバッチサイズ、$C$はカテゴリの総数、$K$はクラスの総数である。


\section{実験}

\subsection{実験設定}

実験は、各手法の正答率を測定するものと、提案手法における予測レーティングと
正解レーティングの平均二乗誤差(RMSE)を測定するものの2つを行った。
RMSEの計算において、正解または予測レーティングが0点であるものは評価から省いた。

比較手法として、(1) Quocら\cite{quoc14}によるPV-DM、及び、
提案手法における分類器の入力を変えた2つの手法、
(2) ASV (Averaged Sentence Vector)と(3) Weighted ASVを用いた。
これらの手法と提案手法に用いる分類器の入力を
表\ref{tab:MethodFeatures}に列挙する。

\begin{table}[b!]
  \caption{各手法に用いられる特徴量}
  \centering
  \begin{tabularx}{\linewidth}{l | X} \label{tab:MethodFeatures}
    手法 & 特徴量 \\
    \hline
    PV-DM & レビュー全体の文書ベクトル \\
    \hline
    ASV & レビュー内で平均した文ベクトル \\
    \hline
    Weighted ASV & レビュー内で重み付け平均によって圧縮された文ベクトル \\
    \hline
    提案手法 & レビュー全体の文書ベクトル、\\
             & レビュー内で重み付け平均によって圧縮された文ベクトル \\
  \end{tabularx}
\end{table}

%ASVとWeighted ASVの比較によって、
%文の位置関係が分類に対して重要であるかが示される。
%基準手法と提案手法、また、Weighted ASVと提案手法の基準手法の比較によって、
%文書ベクトルと文ベクトルを同時に特徴量として用いることが
%有効であるかが示される。

データセットとしては、先行研究\cite{fujitani15}と同様に、
ホテル予約サイト楽天トラベルにおけるレビュー337,266件からレビューの番号順に
訓練データ300,000件、開発データ10,000件、評価データ10,000件を用いた。

%レーティングのRMSEを測定する実験は、上記の正答率を測定する
%実験で得られた予測レーティングを用いて行った。
%正解レーティングまたは予測レーティングが0点であるものは評価から省いている。

表\ref{tab:ParametersOfMethods}に各手法におけるニューラルネットワークの
パラメータ設定を示す。
全ての手法において、中間層の数は1、入力層及び中間層におけるドロップアウト率は
それぞれ0.2と0.5で共通である。
Weighted ASVと提案手法において圧縮された文ベクトルの数はそれぞれ3つと2つとした。
全ての実験において文書及び文ベクトルについては、
学習回数は1,024回、学習する単語の範囲は前3単語、単語の最少出現回数は5回、
ネガティブサンプリングの回数は5回、ベクトルの次元数は600次元に
設定し学習したものを用いた。

\begin{table}[b!]
  \caption{各手法のパラメータ設定}
  \centering
  \begin{tabular}{l | r r} \label{tab:ParametersOfMethods}
    手法 & 学習回数 & 中間層でのユニット数 \\
    \hline
    PV-DM & 20 & 512 \\
    ASV & 55 & 256 \\
    Weighted ASV & 24 & 256 \\
    提案手法 & 30 & 512 \\
  \end{tabular}
\end{table}


\subsection{結果と考察}

まず、提案手法と3つの比較手法、従来手法\cite{fujitani15}を
正答率で比較したものを表\ref{tab:Accuracies}に示す。
結果より、提案手法と3つの比較手法全てが従来手法の正答率を上回っている。
提案手法が従来手法\cite{fujitani15}の正答率を
0.0189上回っていることから、提案手法が従来手法\cite{fujitani15}より
正答率において優れていることが分かった。
また、Weighted ASVの正答率がASVの正答率を0.0018上回っていることから、
文の位置関係の考慮がレーティング予測に有効であることが分かった。
%さらに、提案手法がPV-DMやWeighted ASVに比べ高い正答率を示していることから、
さらに、提案手法がWeighted ASVに比べ高い正答率を示していることから、
文書ベクトルと文ベクトルを同時に特徴量として用いることがレーティング予測に
有効であることが分かった。
これは文書ベクトルと文ベクトルがいくらか異なる特徴を学習していることを示す。

\begin{table}[b!]
  \caption{各手法における正答率}
  \centering
  \begin{tabular}{l | r} \label{tab:Accuracies}
    手法 & 正答率 \\
    \hline
    従来手法\cite{fujitani15}  & 0.4832 \\
    PV-DM & 0.4969 \\
    ASV & 0.4848 \\
    Weighted ASV & 0.4866 \\
    提案手法 & \textbf{0.5021} \\
  \end{tabular}
\end{table}

次に、表\ref{tab:RMSEs}にレーティングのRMSEを測定した結果を示す。
提案手法は従来手法\cite{fujitani15}が苦手としていた
食事と風呂のカテゴリにおいてそれぞれ0.58及び0.27だけ低い誤差を示した。
藤谷ら\cite{fujitani15}より、本実験で用いたデータセットには、
食事のカテゴリにおいて0点が付与されたレビューが108,079件存在する。
また、風呂のカテゴリでは13,332件、設備のカテゴリでは2,011件存在し、
他のカテゴリでは0件である。
一般に、0点はユーザが何らかの理由でレーティング不可能と判断したことを示す。
よって、提案手法は従来手法\cite{fujitani15}よりレビュー中の上記のような意味を
よく捉えていると考えられる。
また、その他全てのカテゴリにおいても提案手法は従来手法より低い誤差を示した。

\begin{table}[b!]
  \caption{提案手法と従来手法\cite{fujitani15}におけるレーティングのRMSE}
  \centering
  \begin{tabular}{l | r r} \label{tab:RMSEs}
    手法 & 提案手法 & 従来手法\cite{fujitani15} \\
    \hline
    立地      & 0.88 & 0.97 \\
    部屋      & 0.90 & 0.97 \\
    食事      & 0.95 & 1.53 \\
    風呂      & 1.00 & 1.27 \\
    サービス  & 0.87 & 0.94 \\
    設備      & 0.93 & 0.95 \\
    総合      & 0.74 & 0.81 \\
  \end{tabular}
\end{table}



\section{結論}

本研究では、多カテゴリにおける評判分類問題について、
レビュー全体の文書ベクトルに加え重み付け平均された文ベクトルを用いた手法を
提案した。

実験では、従来手法\cite{fujitani15}に比べ提案手法が0.0189高い正答率を示した。
また、提案手法が比較手法よりも高い正答率を示したことから、
レビュー内の文の並びが評判分類に重要であること、及び、
文書ベクトルと文ベクトルがレビューのいくらか異なる特徴を捉えていることが
分かった。

今後の課題は、文書や文の分散表現を生成する過程を
ニューラルネットワークによる分類器に統合することである。
これによって、学習方法の柔軟性を高めると共にさらなる正答率の向上を目指す。

%今後の課題は、提案手法の中で2つに分かれているモデルの統合である。
%
%提案手法は、分類すべき文書とそれが含む文の分散表現を生成する段階、及び、
%それらを用いて分類を行う段階の2つの段階に分かれている。
%このことは、問題を2つに分けることで個々の問題を単純にしているが、
%同時に文書の分類を一つずつ行うことを難しくしている。
%また、文書や文の分散表現を事前に生成するための
%PV-DMのパラメータは、実際には最大の正答率を達成するため
%分類器のパラメータとして最適化されることが望ましい。
%
%今後は、これらの問題を解決するために、文書や文の分散表現を生成する過程を
%ニューラルネットワークによる分類器に統合する。
%これによって、学習方法の柔軟性を高めると共にさらなる正答率の向上を目指す。



\section*{謝辞}
本研究において、楽天株式会社よりホテル予約サイト楽天トラベルにおける
レビューデータを使用させていただきました。
この場を借りて深く感謝致します。



\bibliographystyle{jplain}
\begin{thebibliography}{9}
\bibitem{fujitani15}
  藤谷宣典ら,
  隠れ状態を用いたホテルレビューのレーティング予測.
  言語処理学会第21回年次大会, 2015.
\bibitem{quoc14}
  Quoc Le, and Tomas Mikolov,
  Distributed Representations of Sentences and Documents.
  ICML 2014, 2014.
\bibitem{nal14}
  Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom,
  A Convolutional Neural Network for Modelling Sentences.
  ACL 2014, 2014.
\bibitem{rie14}
  Rie Johnson, and Tong Zhang,
  Effective Use of Word Order for Text Categorization
  with Convolutional Neural Networks.
  NAACL 2015, 2015.
\bibitem{duyu15}
  Duyu Tang, Bing Qin, and Ting Liu,
  Learning Semantic Representation of Users and Products
  for Document Level Sentiment Classification.
  ACL 2015, 2015.
\bibitem{yoshua03}
  Yoshua Bengio et al,
  A Neural Probabilistic Language Model.
  The Journal of Machine Learning Research 3, 2003.
\bibitem{mihai12}
  Mihai Surdeanu et al,
  Multi-instance Multi-label Learning for Relation Extraction.
  CoNLL 2012, 2012.
\end{thebibliography}

\end{document}
